{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82tshPeJ78xB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Install and load the latest versions of TensorFlow and Keras. Print their versions.\n",
        "Q2. Load the Wine Quality dataset and explore its dimensions.\n",
        "Dataset link:\n",
        "Q3. Check for null values, identify categorical variables, and encode them.\n",
        "Q4. Separate the features and target variables from the dataframe.\n",
        "Q5. Perform a train-test split and divide the data into training, validation, and test datasets.\n",
        "Q6. Perform scaling on the dataset.\n",
        "Q7. Create at least 2 hidden layers and an output layer for the binary categorical variables.\n",
        "Q8. Create a Sequential model and add all the layers to it.\n",
        "Q9. Implement a TensorBoard callback to visualize and monitor the model's training process.\n",
        "Q10. Use Early Stopping to prevent overfitting by monitoring a chosen metric and stopping the training if\n",
        "no improvement is observed.\n",
        "Q11. Implement a ModelCheckpoint callback to save the best model based on a chosen metric during\n",
        "training.\n",
        "Q12. Print the model summary.\n",
        "Q13. Use binary cross-entropy as the loss function, Adam optimizer, and include the metric ['accuracy'].\n",
        "Q14. Compile the model with the specified loss function, optimizer, and metrics.\n",
        "Q15. Fit the model to the data, incorporating the TensorBoard, Early Stopping, and ModelCheckpoint\n",
        "callbacks.\n",
        "Q16. Get the model's parameters.\n",
        "Q17. Store the model's training history as a Pandas DataFrame.\n",
        "Q18. Plot the model's training history.\n",
        "Q19. Evaluate the model's performance using the test data."
      ],
      "metadata": {
        "id": "W5QznT7T8Cho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: Install and load the latest versions of TensorFlow and Keras.\n",
        "# Note: Make sure you have the required libraries installed in your environment.\n",
        "# You can install them using: pip install tensorflow keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")\n",
        "\n",
        "# Q2: Load the Wine Quality dataset and explore its dimensions.\n",
        "import pandas as pd\n",
        "\n",
        "# Replace 'winequality-white.csv' with the actual filename\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
        "wine_data = pd.read_csv(url, sep=';')\n",
        "\n",
        "# Display dataset dimensions\n",
        "print(f\"Dataset dimensions: {wine_data.shape}\")\n",
        "\n",
        "# Q3: Check for null values, identify categorical variables, and encode them.\n",
        "# Assuming categorical variables are non-numeric, we'll encode them using one-hot encoding.\n",
        "wine_data_encoded = pd.get_dummies(wine_data, columns=['categorical_column1', 'categorical_column2'])\n",
        "\n",
        "# Check for null values\n",
        "print(\"Null values:\\n\", wine_data_encoded.isnull().sum())\n",
        "\n",
        "# Q4: Separate the features and target variables from the dataframe.\n",
        "X = wine_data_encoded.drop('target_column', axis=1)\n",
        "y = wine_data_encoded['target_column']\n",
        "\n",
        "# Q5: Perform a train-test split and divide the data into training, validation, and test datasets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Q6: Perform scaling on the dataset.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Q7-Q11: Create model, callbacks, and training setup\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from datetime import datetime\n",
        "\n",
        "# Q7: Create at least 2 hidden layers and an output layer for binary categorical variables.\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Q8: Create a Sequential model and add all the layers to it.\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Q9: Implement a TensorBoard callback to visualize and monitor the model's training process.\n",
        "log_dir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Q10: Use Early Stopping to prevent overfitting by monitoring a chosen metric.\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Q11: Implement a ModelCheckpoint callback to save the best model based on a chosen metric.\n",
        "model_checkpoint_callback = ModelCheckpoint(\"best_model.h5\", monitor='val_accuracy', save_best_only=True)\n",
        "\n",
        "# Q12: Print the model summary.\n",
        "model.summary()\n",
        "\n",
        "# Q13-Q14: Compile the model with the specified loss function, optimizer, and metrics.\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Q15: Fit the model to the data, incorporating callbacks.\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=[tensorboard_callback, early_stopping_callback, model_checkpoint_callback]\n",
        ")\n",
        "\n",
        "# Q16: Get the model's parameters.\n",
        "model_params = model.get_weights()\n",
        "print(\"Model Parameters:\", model_params)\n",
        "\n",
        "# Q17: Store the model's training history as a Pandas DataFrame.\n",
        "history_df = pd.DataFrame(history.history)\n",
        "\n",
        "# Q18: Plot the model's training history.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_df.plot(figsize=(10, 6))\n",
        "plt.title('Model Training History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Q19: Evaluate the model's performance using the test data.\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "id": "0oZm7MHM8Del"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2GLQutxR8I85"
      }
    }
  ]
}