{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiBBtILM2LXS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: Use any GAN of your choice (preferably DCGAN) to generate images from noise. Perform the\n",
        "following experiments.\n",
        "A. Use the CIFAR 10 database to learn the GAN network. Generate images once the learning is complete.\n",
        "B. Plot generator and discriminator losses and show how can you ascertain the convergence of the GAN\n",
        "training process."
      ],
      "metadata": {
        "id": "jX08h89s2M12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the generator and discriminator networks\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf, nc):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 2, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc, ndf):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "\n",
        "# Set hyperparameters\n",
        "nz = 100  # Size of the latent vector\n",
        "ngf = 64  # Generator feature maps\n",
        "ndf = 64  # Discriminator feature maps\n",
        "nc = 3    # Number of channels in the images\n",
        "\n",
        "# Create generator and discriminator instances\n",
        "netG = Generator(nz, ngf, nc).to(device)\n",
        "netD = Discriminator(nc, ndf).to(device)\n",
        "\n",
        "# Define loss function and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Set up data loader for CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "dataset = datasets.CIFAR10(root=\"./data\", download=True, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4)\n",
        "\n",
        "# Training the GAN\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        # Update discriminator\n",
        "         netD.zero_grad()\n",
        "    real_images = data[0].to(device)\n",
        "    batch_size = real_images.size(0)\n",
        "    label = torch.full((batch_size,), 1, device=device)\n",
        "\n",
        "    output = netD(real_images).view(-1)\n",
        "    errD_real = criterion(output, label[:batch_size])  # Fix here\n",
        "    errD_real.backward()\n",
        "\n",
        "    noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "    fake_images = netG(noise)\n",
        "    label.fill_(0)\n",
        "    output = netD(fake_images.detach()).view(-1)\n",
        "    errD_fake = criterion(output, label[:batch_size])  # Fix here\n",
        "    errD_fake.backward()\n",
        "    optimizerD.step()\n",
        "\n",
        "    # Update generator\n",
        "    netG.zero_grad()\n",
        "    label.fill_(1)\n",
        "    output = netD(fake_images).view(-1)\n",
        "    errG = criterion(output, label[:batch_size])  # Fix here\n",
        "    errG.backward()\n",
        "    optimizerG.step()\n",
        "\n",
        "    # Print training statistics\n",
        "    if i % 100 == 0:\n",
        "        print(f\"[{epoch}/{num_epochs}][{i}/{len(dataloader)}] Loss_D: {errD.item()} Loss_G: {errG.item()}\")\n",
        "        # Update generator\n",
        "        netG.zero_grad()\n",
        "        label.fill_(1)\n",
        "        output = netD(fake_images).view(-1)\n",
        "        errG = criterion(output, label)\n",
        "        errG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Print training statistics\n",
        "        if i % 100 == 0:\n",
        "            print(f\"[{epoch}/{num_epochs}][{i}/{len(dataloader)}] Loss_D: {errD.item()} Loss_G: {errG.item()}\")\n",
        "\n",
        "# Save the trained models\n",
        "torch.save(netG.state_dict(), \"generator.pth\")\n",
        "torch.save(netD.state_dict(), \"discriminator.pth\")\n",
        "\n",
        "# Generate images using the trained generator\n",
        "with torch.no_grad():\n",
        "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "    fake_images = netG(fixed_noise).detach().cpu()\n",
        "\n",
        "# Plot generated images\n",
        "fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    ax.imshow(np.transpose(fake_images[i], (1, 2, 0)))\n",
        "    ax.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "92C_oCov2OU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to store generator and discriminator losses during training\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "# Training loop (inside the main loop)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        # ... (same training loop as before)\n",
        "\n",
        "        # Append losses to lists\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append((errD_real + errD_fake).item())\n",
        "\n",
        "# Plot the losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(G_losses, label=\"Generator Loss\")\n",
        "plt.plot(D_losses, label=\"Discriminator Loss\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "237w2_SJ3IBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7xo4tWfE3QAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Fine-tuning Take a ResNet50 model and the database to be used for this question is CIFAR-10.\n",
        "Remove its classification layer and place a 2-layer neural network followed by a Softmax layer. Calculate\n",
        "classification accuracy on a train set, test set, and plot accuracies over epochs when:\n",
        "A. The complete network is trained from scratch (i.e, random weights)\n",
        "B. A pre-trained ResNet50 on ImageNet weights is used and only the neural network layers are trained\n",
        "(i.e, weights of layers of ResNet50 are kept frozen and unchanged)\n",
        "C. A pre-trained ResNet50 on ImageNet weights is used and all the layers are adapted (i.e, weights of\n",
        "layers of ResNet50 are also updated now)\n",
        "D. Using a ResNet50 model for CIFAR-10, propose your own domain adaptation algorithm. To get full\n",
        "credit for this part, the accuracy on the test set should be more than what was reported in part 3. You\n",
        "may build upon part (3) to propose your own algorithm. Explain why your proposed algorithm is\n",
        "working better. You may use any training data as long as it involves using other datasets (on which\n",
        "you'll adapt CIFAR-10)."
      ],
      "metadata": {
        "id": "dn-3I7Gf3YlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Let's break down each part of the question and provide code snippets for each scenario:\n",
        "\n",
        "### A. Train the Complete Network from Scratch:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the model\n",
        "class CustomResNet50(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CustomResNet50, self).__init__()\n",
        "        resnet = models.resnet50(pretrained=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-1])  # Remove the last classification layer\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "# Initialize and train the model\n",
        "model_scratch = CustomResNet50().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_scratch = optim.SGD(model_scratch.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    train_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        accuracy = correct / total\n",
        "        train_accuracies.append(accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return train_accuracies\n",
        "\n",
        "# Train the complete network from scratch\n",
        "train_accuracies_scratch = train(model_scratch, train_loader, criterion, optimizer_scratch)\n",
        "\n",
        "# Plot accuracies over epochs\n",
        "plt.plot(train_accuracies_scratch, label='Training Accuracy (Scratch)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Accuracy Over Epochs (Scratch)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### B. Fine-tune Only the Neural Network Layers with Pre-trained ResNet50 Weights:\n",
        "\n",
        "```python\n",
        "# Load pre-trained ResNet50 model\n",
        "model_pretrained = models.resnet50(pretrained=True)\n",
        "model_pretrained = nn.Sequential(*list(model_pretrained.children())[:-1])  # Remove the last classification layer\n",
        "\n",
        "# Add custom layers\n",
        "model_pretrained.fc_layers = nn.Sequential(\n",
        "    nn.Linear(2048, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 10),  # 10 classes for CIFAR-10\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "# Fine-tune only the neural network layers\n",
        "model_pretrained.fc_layers.parameters()\n",
        "\n",
        "# Initialize and train the model\n",
        "model_pretrained = model_pretrained.to(device)\n",
        "optimizer_pretrained = optim.SGD(model_pretrained.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train only the neural network layers\n",
        "train_accuracies_pretrained = train(model_pretrained, train_loader, criterion, optimizer_pretrained)\n",
        "\n",
        "# Plot accuracies over epochs\n",
        "plt.plot(train_accuracies_pretrained, label='Training Accuracy (Pretrained)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Accuracy Over Epochs (Pretrained)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### C. Fine-tune All Layers (Including ResNet50) with Pre-trained Weights:\n",
        "\n",
        "```python\n",
        "# Load pre-trained ResNet50 model\n",
        "model_all_layers = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the classification layer\n",
        "model_all_layers.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 10),  # 10 classes for CIFAR-10\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "# Fine-tune all layers\n",
        "model_all_layers.parameters()\n",
        "\n",
        "# Initialize and train the model\n",
        "model_all_layers = model_all_layers.to(device)\n",
        "optimizer_all_layers = optim.SGD(model_all_layers.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train all layers\n",
        "train_accuracies_all_layers = train(model_all_layers, train_loader, criterion, optimizer_all_layers)\n",
        "\n",
        "# Plot accuracies over epochs\n",
        "plt.plot(train_accuracies_all_layers, label='Training Accuracy (All Layers)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Accuracy Over Epochs (All Layers)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### D. Domain Adaptation Algorithm:\n",
        "\n",
        "For domain adaptation, you may use techniques such as domain adversarial training or self-training with pseudo-labels on other datasets. The key is to leverage data from a source domain (e.g., ImageNet) to improve performance on the target domain (CIFAR-10). Here's a simplified example using domain adversarial training:\n",
        "\n",
        "```python\n",
        "# Import necessary libraries\n",
        "from torch.autograd import Function\n",
        "\n",
        "# Define the domain discriminator\n",
        "class DomainDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DomainDiscriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(1024, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Initialize models and optimizers\n",
        "model_domain_adaptation = models.resnet50(pretrained=True)\n",
        "model_domain_adaptation.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 10),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "discriminator = DomainDiscriminator()\n",
        "\n",
        "model_domain_adaptation = model_domain_adaptation.to(device)\n",
        "discriminator = discriminator.to(device)\n",
        "\n",
        "optimizer_domain_adaptation = optim.SGD([\n",
        "    {'params': model_domain_adaptation.parameters()},\n",
        "    {'params': discriminator.parameters()}\n",
        "], lr=0.001, momentum=0.9)\n",
        "\n",
        "# Define the domain adversarial training function\n",
        "class GradientReverse\n",
        "\n",
        "(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output.neg() * ctx.alpha, None\n",
        "\n",
        "def grad_reverse(x, alpha):\n",
        "    return GradientReverse.apply(x, alpha)\n",
        "\n",
        "# Domain adversarial training loop\n",
        "def train_domain_adaptation(model, discriminator, dataloader_source, dataloader_target, criterion, optimizer, num_epochs=10, alpha=0.01):\n",
        "    model.train()\n",
        "    discriminator.train()\n",
        "    train_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for (source_inputs, source_labels), (target_inputs, _) in zip(dataloader_source, dataloader_target):\n",
        "            source_inputs, source_labels = source_inputs.to(device), source_labels.to(device)\n",
        "            target_inputs = target_inputs.to(device)\n",
        "\n",
        "            # Source domain classification\n",
        "            optimizer.zero_grad()\n",
        "            outputs_source = model(source_inputs)\n",
        "            loss_source = criterion(outputs_source, source_labels)\n",
        "            loss_source.backward()\n",
        "\n",
        "            # Domain adaptation\n",
        "            optimizer_domain_adaptation.zero_grad()\n",
        "            features = model_domain_adaptation(source_inputs)\n",
        "            features = grad_reverse(features, alpha)\n",
        "            domain_labels_source = torch.ones(source_inputs.size(0), 1).to(device)\n",
        "            outputs_domain_source = discriminator(features)\n",
        "            loss_domain_source = criterion(outputs_domain_source, domain_labels_source)\n",
        "\n",
        "            features = model_domain_adaptation(target_inputs)\n",
        "            features = grad_reverse(features, alpha)\n",
        "            domain_labels_target = torch.zeros(target_inputs.size(0), 1).to(device)\n",
        "            outputs_domain_target = discriminator(features)\n",
        "            loss_domain_target = criterion(outputs_domain_target, domain_labels_target)\n",
        "\n",
        "            loss_domain_adaptation = loss_domain_source + loss_domain_target\n",
        "            loss_domain_adaptation.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer_domain_adaptation.step()\n",
        "\n",
        "            # Print training statistics\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Epoch {epoch+1}/{num_epochs}, Loss Source: {loss_source:.4f}, Loss Domain Adaptation: {loss_domain_adaptation:.4f}\")\n",
        "\n",
        "        # Evaluate on the target domain\n",
        "        accuracy_target = evaluate(model, dataloader_target)\n",
        "        train_accuracies.append(accuracy_target)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Accuracy on Target Domain: {accuracy_target:.4f}\")\n",
        "\n",
        "    return train_accuracies\n",
        "\n",
        "# Train the model with domain adaptation\n",
        "train_accuracies_domain_adaptation = train_domain_adaptation(model_domain_adaptation, discriminator, train_loader, test_loader, criterion, optimizer_domain_adaptation)\n",
        "\n",
        "# Plot accuracies over epochs\n",
        "plt.plot(train_accuracies_domain_adaptation, label='Accuracy with Domain Adaptation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy on Target Domain with Domain Adaptation')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "This example uses a simple domain adversarial training approach. You may need to fine-tune and adjust hyperparameters based on the specific characteristics of your source and target domains. Additionally, you may explore other advanced domain adaptation techniques, such as self-training, consistency regularization, or domain adversarial neural networks (DANN)."
      ],
      "metadata": {
        "id": "zeMfy0za3jCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Implement a gan from scratch using Keras to generate celebrity faces from noise using this\n",
        "data-: https://www.kaggle.com/datasets/jessicali9530/celeba-dataset\n",
        "Use cases found for GAN:\n",
        "• Super-resolution: increasing the resolution of input images\n",
        "• Colorise blank and white images\n",
        "• image inpainting - fill missing blocks in images\n",
        "• Anime face generation\n",
        "• font generation\n",
        "• style transfer\n",
        "• human face generation\n",
        "• image to emoji\n",
        "• GAN for data augmentation\n",
        "• Face ageing GAN\n",
        "• front facial view generation from images provided of different sides\n",
        "• Photo blending- blending 2 images"
      ],
      "metadata": {
        "id": "vR2Q39jc3koS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure, I'll provide you with a simple implementation of a Generative Adversarial Network (GAN) using Keras to generate celebrity faces from noise. For this example, we'll focus on generating realistic celebrity faces. You can further modify the architecture and training process to adapt to specific use cases mentioned.\n",
        "\n",
        "Please note that training a GAN can be computationally expensive and may take a long time. Also, the provided code is a basic example; you may need to experiment with the model architecture, hyperparameters, and other settings to achieve better results.\n",
        "\n",
        "### Install Required Libraries\n",
        "\n",
        "Make sure you have Keras and TensorFlow installed:\n",
        "\n",
        "```bash\n",
        "pip install keras tensorflow\n",
        "```\n",
        "\n",
        "### GAN Implementation for Celebrity Faces Generation\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input\n",
        "from keras.optimizers import Adam\n",
        "from keras import initializers\n",
        "\n",
        "# Load the CelebA dataset\n",
        "# Download the dataset from https://www.kaggle.com/jessicali9530/celeba-dataset\n",
        "# Extract the images into a folder and provide the path below\n",
        "# For this example, I'm assuming you have images in a 'celeba' folder\n",
        "# You may need to preprocess the images based on your specific use case\n",
        "# (e.g., resizing to a fixed size)\n",
        "images_path = 'path_to_celeba_images_folder'\n",
        "\n",
        "# Define image dimensions\n",
        "img_rows, img_cols, channels = 64, 64, 3\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "latent_dim = 100  # Size of the latent space\n",
        "\n",
        "# Load and preprocess CelebA images\n",
        "def load_celeba_data(images_path):\n",
        "    # Load images and normalize to the range [-1, 1]\n",
        "    images = np.load(images_path)\n",
        "    images = (images.astype(np.float32) - 127.5) / 127.5\n",
        "    return images\n",
        "\n",
        "celeba_images = load_celeba_data(images_path)\n",
        "\n",
        "# Generator model\n",
        "def build_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_dim=latent_dim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
        "    model.add(Reshape(img_shape))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Discriminator model\n",
        "def build_discriminator(img_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten(input_shape=img_shape))\n",
        "    model.add(Dense(1024, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and compile the discriminator\n",
        "discriminator = build_discriminator(img_shape)\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
        "\n",
        "# Build the generator\n",
        "generator = build_generator(latent_dim)\n",
        "\n",
        "# Build and compile the combined model\n",
        "z = Input(shape=(latent_dim,))\n",
        "img = generator(z)\n",
        "\n",
        "discriminator.trainable = False\n",
        "validity = discriminator(img)\n",
        "\n",
        "combined = Model(z, validity)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
        "\n",
        "# Training the GAN\n",
        "def train_gan(epochs, batch_size, save_interval):\n",
        "    half_batch = batch_size // 2\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Select a random half batch of images\n",
        "        idx = np.random.randint(0, celeba_images.shape[0], half_batch)\n",
        "        imgs = celeba_images[idx]\n",
        "\n",
        "        # Sample noise and generate a half batch of new images\n",
        "        noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator (real classified as ones and generated as zeros)\n",
        "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Train the generator (wants discriminator to mistake images as real)\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        valid_labels = np.ones((batch_size, 1))\n",
        "\n",
        "        g_loss = combined.train_on_batch(noise, valid_labels)\n",
        "\n",
        "        # Plot the progress\n",
        "        print(f\"{epoch} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
        "\n",
        "        # Save generated images at specified intervals\n",
        "        if epoch % save_interval == 0:\n",
        "            save_generated_images(epoch)\n",
        "\n",
        "# Function to save generated images\n",
        "def save_generated_images(epoch):\n",
        "    r, c = 5, 5  # Grid size\n",
        "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c, figsize=(10, 10))\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i, j].imshow(gen_imgs[cnt])\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "    plt.savefig(f\"gan_generated_image_epoch_{epoch}.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Train the GAN\n",
        "epochs = 10000  # You may need more epochs based on your dataset and model complexity\n",
        "batch_size = 64\n",
        "save_interval = 1000\n",
        "\n",
        "train_gan(epochs, batch_size, save_interval)\n",
        "```\n",
        "\n",
        "This is a basic GAN architecture for generating celebrity faces using Keras. You can customize the architecture, hyperparameters, and training loop based on your specific use case. Keep in mind that GAN training can be sensitive to hyperparameters, and it may require experimentation to achieve good results."
      ],
      "metadata": {
        "id": "4adJOIB44Kmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PJgxmMng4NRK"
      }
    }
  ]
}